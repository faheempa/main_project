{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import environment\n",
    "from collections import deque\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_MEMORY = 2000\n",
    "BATCH_SIZE = 256\n",
    "LR = 0.001\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, model, batch_size, data_path):\n",
    "        self.model = model\n",
    "        self.memory = deque(maxlen=MAX_MEMORY)\n",
    "        self.batch_size = batch_size\n",
    "        raw_data = pd.read_csv(data_path)\n",
    "        self.env = environment.Environment(raw_data)\n",
    "\n",
    "    def get_state(self):\n",
    "        return self.env.get_state()\n",
    "\n",
    "    def get_action(self, state):\n",
    "        return torch.argmax(self.model(state))\n",
    "    \n",
    "    def remember(self, state, action, reward):\n",
    "        self.memory.append((state, action, reward))\n",
    "\n",
    "    def train_long_memory(self):\n",
    "        if len(self.memory) > BATCH_SIZE:\n",
    "            mini_sample = random.sample(self.memory, BATCH_SIZE)\n",
    "        else:\n",
    "            mini_sample = self.memory\n",
    "        states, actions, rewards = zip(*mini_sample)\n",
    "        self.train_step(states, actions, rewards)\n",
    "\n",
    "    def train_short_memory(self, state, action, reward):\n",
    "        self.train_step(state, action, reward)\n",
    "\n",
    "\n",
    "    def get_target(self, actions, rewards):\n",
    "        # trick:\n",
    "        # if action is \"sell\" and reward is positive, then target is \"sell\"\n",
    "        # if action is \"sell\" and reward is negative, then target is \"buy\"\n",
    "        # if action is \"sell\" and reward is zero, then target is \"hold\"\n",
    "        # if action is \"buy\" and reward is positive, then target is \"buy\"\n",
    "        # if action is \"buy\" and reward is negative, then target is \"sell\"\n",
    "        # if action is \"buy\" and reward is zero, then target is \"hold\"\n",
    "        # if action is \"hold\" and reward is positive, then target is \"buy\"\n",
    "        # if action is \"hold\" and reward is negative, then target is \"sell\"\n",
    "        # if action is \"hold\" and reward is zero, then target is \"hold\"\n",
    "        # \"buy\"->0, \"sell\"->1, \"hold\"->2\n",
    "        target = torch.zeros(len(actions))\n",
    "        for i, (a, r) in enumerate(zip(actions, rewards)):\n",
    "            if r==0:\n",
    "                target[i] = 2\n",
    "                continue\n",
    "            if a==1:\n",
    "                target[i] = int(r>0)\n",
    "            elif a==0:\n",
    "                target[i] = int(r<0)\n",
    "            else:\n",
    "                target[i] = int(r<0)\n",
    "\n",
    "        target.reshape(-1, 1)\n",
    "        return target\n",
    "    \n",
    "    def train_step(self, states, actions, rewards):\n",
    "        states = torch.tensor(states, dtype=torch.float)\n",
    "        actions = torch.tensor(actions, dtype=torch.int32)\n",
    "        rewards = torch.tensor(rewards, dtype=torch.int32)\n",
    "        target = self.get_target(actions, rewards)\n",
    "\n",
    "        if len(states.shape) == 1:\n",
    "            states = torch.unsqueeze(states, 0)\n",
    "            actions = torch.unsqueeze(actions, 0)\n",
    "            rewards = torch.unsqueeze(rewards, 0)\n",
    "            target = torch.unsqueeze(target, 0)\n",
    "\n",
    "        self.model.optimizer.zero_grad()\n",
    "        output = self.model(states)\n",
    "        loss = self.model.loss(actions, target)\n",
    "        loss.backward()\n",
    "        self.model.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESN(nn.Module):\n",
    "    def __init__(self, input_size, reservoir_size, output_size, spectral_radius=0.9, LR=0.001):\n",
    "        super(ESN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.reservoir_size = reservoir_size\n",
    "\n",
    "        # Initialize reservoir weights\n",
    "        self.Win = nn.Parameter(torch.randn(reservoir_size, input_size))\n",
    "        self.W = nn.Parameter(torch.randn(reservoir_size, reservoir_size))\n",
    "\n",
    "        # Scaling W to have spectral radius = spectral_radius\n",
    "        self.W.data *= spectral_radius / torch.max(torch.abs(torch.linalg.eigvals(self.W)))\n",
    "\n",
    "        # Output layer\n",
    "        self.Wout = nn.Linear(reservoir_size, output_size)\n",
    "\n",
    "        # lr, loss and optimizer\n",
    "        self.lr=LR\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=LR)\n",
    "\n",
    "    def forward(self, input_data, initial_state=None):\n",
    "        if initial_state is None:\n",
    "            state = torch.zeros((input_data.size(0), self.reservoir_size)).to(device)\n",
    "        else:\n",
    "            state = initial_state\n",
    "\n",
    "        state = torch.tanh(torch.matmul(input_data, self.Win.t()) + torch.matmul(state, self.W.t()))\n",
    "        state = torch.tanh(self.Wout(state))\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, num_hidden, num_layers, output_size, esn):\n",
    "        super().__init__()\n",
    "\n",
    "        # store parameters\n",
    "        self.input_size = input_size\n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # RNN Layer (notation: LSTM \\in RNN)\n",
    "        self.lstm = nn.LSTM(input_size, num_hidden, num_layers)\n",
    "\n",
    "        # linear layer for output\n",
    "        self.out = nn.Linear(num_hidden, output_size)\n",
    "\n",
    "        # esn\n",
    "        self.ESN = esn\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(f\"Input: {list(x.shape)}\")\n",
    "        # pass the input through the ESN\n",
    "        x = self.ESN(x)\n",
    "        print(f\"Output-ESN: {list(x.shape)}\")\n",
    "\n",
    "        # run through the RNN layer\n",
    "        y, hidden = self.lstm(x)\n",
    "        print(f\"RNN-cell: {list(hidden[1].shape)}\")\n",
    "        print(f\"RNN-hidden: {list(hidden[0].shape)}\")\n",
    "        print(f\"RNN-out: {list(y.shape)}\")\n",
    "\n",
    "        # pass the RNN output through the linear output layer\n",
    "        o = self.out(y)\n",
    "        print(f\"Output: {list(o.shape)}\")\n",
    "\n",
    "        return o[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [1, 1, 4]\n",
      "Output-ESN: [1, 1, 128]\n",
      "RNN-cell: [3, 1, 512]\n",
      "RNN-hidden: [3, 1, 512]\n",
      "RNN-out: [1, 1, 512]\n",
      "Output: [1, 1, 3]\n"
     ]
    }
   ],
   "source": [
    "esn_input_size = 4\n",
    "esn_reservoir_size = 1024\n",
    "esn_output_size = 128\n",
    "lstm_input_size = 128\n",
    "lstm_num_hidden = 512\n",
    "lstm_num_layers = 3\n",
    "lstm_output_size = 3\n",
    "\n",
    "# test\n",
    "esn = ESN(esn_input_size, esn_reservoir_size, esn_output_size)\n",
    "lstm = LSTM(lstm_input_size, lstm_num_hidden, lstm_num_layers, lstm_output_size, esn)\n",
    "input_data = torch.randn(1, 1, esn_input_size)\n",
    "action = torch.argmax(lstm(input_data)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [10, 4]\n",
      "Output-ESN: [10, 128]\n",
      "RNN-cell: [3, 512]\n",
      "RNN-hidden: [3, 512]\n",
      "RNN-out: [10, 512]\n",
      "Output: [10, 3]\n",
      "state: tensor([[ -9.0040, -11.3140, -39.3180, -32.8940],\n",
      "        [-32.7570, -29.0250, -28.5720, -29.6440],\n",
      "        [-29.4300,  -4.5390,   5.3510,  14.1080],\n",
      "        [ 13.4120, -10.8700,   3.2980, -10.0830],\n",
      "        [ -8.9850,  -5.5100,   3.9490,   3.3310],\n",
      "        [  2.9920,  34.6410,  -0.9330,  33.6390],\n",
      "        [ 33.6590,  -5.4450,  24.9350, -12.5860],\n",
      "        [-12.5950, -12.5920, -11.6640, -11.6310],\n",
      "        [-11.7270,  -8.5820,  -9.4590,  -7.1490],\n",
      "        [ -7.8730,  -8.3150,  -2.6370,  -4.9050]]), action: 2, reward: -1\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    esn = ESN(esn_input_size, esn_reservoir_size, esn_output_size)\n",
    "    lstm = LSTM(lstm_input_size, lstm_num_hidden, lstm_num_layers, lstm_output_size, esn)\n",
    "    agent = Agent(lstm, BATCH_SIZE, \"crypto_data/train_data.csv\")\n",
    "    state = agent.env.reset()\n",
    "    action = agent.get_action(state)\n",
    "    new_state, reward, done = agent.env.step(action)\n",
    "    agent.remember(state, action, reward)\n",
    "    print(f\"state: {state}, action: {action}, reward: {reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_state.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
