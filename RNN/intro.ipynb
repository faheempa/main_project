{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(9, 16)\n"
     ]
    }
   ],
   "source": [
    "# set layer parameters\n",
    "input_size  =  9 # number of features to extract (e.g., number of data channels)\n",
    "hidden_size = 16 # number of units in the hidden state\n",
    "num_layers  =  1 # number of vertical stacks of hidden layers (note: only the final layer gives an output)\n",
    "actfun      = 'tanh'\n",
    "bias        = True\n",
    "\n",
    "# create an RNN instance\n",
    "rnn = nn.RNN(input_size,hidden_size,num_layers,nonlinearity=actfun,bias=bias)\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Input shape: [5, 2, 9]\n",
      "Hidden shape: [1, 2, 16]\n",
      "Output shape: [5, 2, 16]\n"
     ]
    }
   ],
   "source": [
    "# set data parameters\n",
    "seqlength = 5\n",
    "batchsize = 2\n",
    "\n",
    "# create some data\n",
    "X = torch.rand(seqlength,batchsize,input_size)\n",
    "\n",
    "# create a hidden layer (typically initialized as zeros)\n",
    "hidden = torch.zeros(num_layers,batchsize,hidden_size)\n",
    "\n",
    "\n",
    "# run some data through the model and show the output sizes\n",
    "y,h = rnn(X,hidden)\n",
    "print(f' Input shape: {list(X.shape)}')\n",
    "print(f'Hidden shape: {list(h.shape)}')\n",
    "print(f'Output shape: {list(y.shape)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2455, -0.1427,  0.4452,  0.5793, -0.1998,  0.0557,  0.3951,\n",
      "          -0.0745, -0.1638,  0.4240,  0.3529, -0.0567,  0.0738,  0.2977,\n",
      "          -0.5307, -0.0352],\n",
      "         [-0.0842, -0.3568,  0.5988,  0.4930, -0.1842,  0.0239,  0.5359,\n",
      "          -0.3283,  0.1985,  0.4120,  0.5404, -0.4136,  0.2395,  0.3156,\n",
      "          -0.5292,  0.0738]]], grad_fn=<StackBackward0>)\n",
      "\n",
      "\n",
      "\n",
      "tensor([[[-0.2455, -0.1427,  0.4452,  0.5793, -0.1998,  0.0557,  0.3951,\n",
      "          -0.0745, -0.1638,  0.4240,  0.3529, -0.0567,  0.0738,  0.2977,\n",
      "          -0.5307, -0.0352],\n",
      "         [-0.0842, -0.3568,  0.5988,  0.4930, -0.1842,  0.0239,  0.5359,\n",
      "          -0.3283,  0.1985,  0.4120,  0.5404, -0.4136,  0.2395,  0.3156,\n",
      "          -0.5292,  0.0738]]], grad_fn=<StackBackward0>)\n",
      "\n",
      "\n",
      "\n",
      "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## Default hidden state is all zeros if nothing specified:\n",
    "y,h1 = rnn(X,hidden)\n",
    "print(h1), print('\\n\\n')\n",
    "\n",
    "y,h2 = rnn(X)\n",
    "print(h2), print('\\n\\n')\n",
    "\n",
    "# they're the same! (meaning default=zeros)\n",
    "print(h1-h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0 has size [16, 9]\n",
      "weight_hh_l0 has size [16, 16]\n"
     ]
    }
   ],
   "source": [
    "# Check out the learned parameters and their sizes\n",
    "for p in rnn.named_parameters():\n",
    "  if 'weight' in p[0]:\n",
    "    print(f'{p[0]} has size {list(p[1].shape)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNnet(nn.Module):\n",
    "  def __init__(self,input_size,num_hidden,num_layers):\n",
    "    super().__init__()\n",
    "\n",
    "    # store parameters\n",
    "    self.input_size = input_size\n",
    "    self.num_hidden = num_hidden\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    # RNN Layer\n",
    "    self.rnn = nn.RNN(input_size,num_hidden,num_layers)\n",
    "    \n",
    "    # linear layer for output\n",
    "    self.out = nn.Linear(num_hidden,1)\n",
    "  \n",
    "  def forward(self,x):\n",
    "    \n",
    "    print(f'Input: {list(x.shape)}')\n",
    "    \n",
    "    # initialize hidden state for first input\n",
    "    hidden = torch.zeros(self.num_layers,batchsize,self.num_hidden)\n",
    "    print(f'Hidden: {list(hidden.shape)}')\n",
    "\n",
    "    # run through the RNN layer\n",
    "    y,hidden = self.rnn(x,hidden)\n",
    "    print(f'RNN-out: {list(y.shape)}')\n",
    "    print(f'RNN-hidden: {list(hidden.shape)}')\n",
    "    \n",
    "    # pass the RNN output through the linear output layer\n",
    "    o = self.out(y)\n",
    "    print(f'Output: {list(o.shape)}')\n",
    "\n",
    "    return o,hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNnet(\n",
      "  (rnn): RNN(9, 16)\n",
      "  (out): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n",
      " \n",
      "rnn.weight_ih_l0 has size [16, 9]\n",
      "rnn.weight_hh_l0 has size [16, 16]\n",
      "rnn.bias_ih_l0 has size [16]\n",
      "rnn.bias_hh_l0 has size [16]\n",
      "out.weight has size [1, 16]\n",
      "out.bias has size [1]\n"
     ]
    }
   ],
   "source": [
    "# create an instance of the model and inspect\n",
    "net = RNNnet(input_size,hidden_size,num_layers)\n",
    "print(net), print(' ')\n",
    "\n",
    "# and check out all learnable parameters\n",
    "for p in net.named_parameters():\n",
    "  print(f'{p[0]} has size {list(p[1].shape)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [5, 2, 9]\n",
      "Hidden: [1, 2, 16]\n",
      "RNN-out: [5, 2, 16]\n",
      "RNN-hidden: [1, 2, 16]\n",
      "Output: [5, 2, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0630, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the model with some data\n",
    "# create some data\n",
    "X = torch.rand(seqlength,batchsize,input_size)\n",
    "y = torch.rand(seqlength,batchsize,1)\n",
    "yHat,h = net(X)\n",
    "\n",
    "# try a loss function\n",
    "lossfun = nn.MSELoss()\n",
    "lossfun(yHat,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
